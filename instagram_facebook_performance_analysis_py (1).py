# -*- coding: utf-8 -*-
"""Instagram_Facebook_Performance_Analysis.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NWPd1WECy0VJLcmCR7wnVvJ38eHve5tn
"""

import pandas as pd

# Google Sheets used for a CSV Files
sheet1_url = "https://docs.google.com/spreadsheets/d/190PBaRZQmYSdIWsId1jufGU1aI4tOSh9wwzAp03eOiY/export?format=csv&gid=0"
sheet2_url = "https://docs.google.com/spreadsheets/d/1W9oZpAf1Q5CwRJDQ1h8Id-6cokPEL5q6sIhI0NlbQGw/export?format=csv&gid=0"

# Dataframes Read into Pandas as Instagrame is df1 and Facebook is df2
df1 = pd.read_csv(sheet1_url)
df2 = pd.read_csv(sheet2_url)

# Display first few rows
print(df1.head())
print(df2.head())

# Cleanig Data Check for missing values
print("Instagram Missing Values:\n", df1.isnull().sum())
print("\nFacebook Missing Values:\n", df2.isnull().sum())

# If no missing value found fill missing values with 0 (or use appropriate methods)
df1.fillna(0, inplace=True)
df2.fillna(0, inplace=True)

#Strip column names to cheack the names properly
df1.columns = df1.columns.str.strip()
print(df1.columns)

# for futher analysis
# Calculate engagement rate by using total likes, total reach and page followers
df1["engagement_rate"] = (df1["Total likes"] + df1["Total reach"]) / df1["Page followers"]

# Average Engagement Rate
avg_engagement = df1["engagement_rate"].mean()
print(f"Average Engagement Rate: {avg_engagement:.2%}")

# Top-Performing Instagram Post
top_instagram_post = df1.sort_values(by="engagement_rate", ascending=False).head(1)
print("Top Instagram Post:\n", top_instagram_post)

#Strip column names of Facebook for correct names
df2.columns = df2.columns.str.strip()
print(df2.columns)

# Calculate CTR by using profile visits and profile impressions
df2["ctr"] = df2["Profile visits"] / df2["Profile impressions"]

# Average CTR
avg_ctr = df2["ctr"].mean()
print(f"Average Click-Through Rate (CTR): {avg_ctr:.2%}")

# To check which facebook ad perform well
# Top Facebook Ad
top_facebook_ad = df2.sort_values(by="ctr", ascending=False).head(1)
print("Top Facebook Ad:\n", top_facebook_ad)

import matplotlib.pyplot as plt
import pandas as pd

# Just for check is the date format is correct to evaluate average engagement rate
# Convert 'date' column to datetime format
df1["Date"] = pd.to_datetime(df1["Date"], format="%d/%m/%Y")

# Group by date and calculate average engagement rate
engagement_trend = df1.groupby("Date")["engagement_rate"].mean()

# Plot
plt.figure(figsize=(10, 5))
plt.plot(engagement_trend.index, engagement_trend.values, marker='o', linestyle='-')
plt.title("Instagram Engagement Trends Over Time")
plt.xlabel("Date")
plt.ylabel("Engagement Rate")
plt.xticks(rotation=45)
plt.grid()
plt.show()

import seaborn as sns
# Used barplot to see which reels Vs. static
plt.figure(figsize=(8, 5))
sns.barplot(x="Page post engagements", y="engagement_rate", data=df1)
plt.title("Engagement Rate by Post Type (Reels vs. Static)")
plt.xlabel("Post Type")
plt.ylabel("Engagement Rate")
plt.show()

import numpy as np
# To countinue analysis perform A/B testing
# Create a new column for A/B testing (Randomly assign 'A' or 'B')
np.random.seed(42)  # For reproducibility
df2["ad_variant"] = np.random.choice(["A", "B"], size=len(df2))

# Check the new column
print(df2[["Date", "ctr", "ad_variant"]].head())

# Group A: CTR values for Ad Variant A
group_a = df2[df2["ad_variant"] == "A"]["ctr"]

# Group B: CTR values for Ad Variant B
group_b = df2[df2["ad_variant"] == "B"]["ctr"]

# Print average CTR for both groups
print(f"Avg CTR for Ad A: {group_a.mean():.2%}")
print(f"Avg CTR for Ad B: {group_b.mean():.2%}")

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import ttest_ind

# For A/B testing shows I used Boxplot to see which ad are performing well
# Randomly Assign Ad Variants (If not available)
np.random.seed(42)
df2["ad_variant"] = np.random.choice(["A", "B"], size=len(df2))

# Split into Groups
group_a = df2[df2["ad_variant"] == "A"]["ctr"]
group_b = df2[df2["ad_variant"] == "B"]["ctr"]

# T-Test
t_stat, p_value = ttest_ind(group_a, group_b)
print(f"T-Test Result: t={t_stat:.3f}, p={p_value:.3f}")

if p_value < 0.05:
    print(" There is a significant difference between Ad A and Ad B")
else:
    print(" No significant difference between Ad A and Ad B")

# Boxplot
plt.figure(figsize=(10, 6))
sns.boxplot(x="ad_variant", y="ctr", data=df2, palette=["#4CAF50", "#FF5733"])
plt.title("A/B Testing: CTR Comparison")
plt.xlabel("Ad Variant")
plt.ylabel("Click-Through Rate")
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load dataset
df1 = pd.read_csv(sheet1_url)
df2 = pd.read_csv(sheet2_url)

# Feature Selection to use for training data
features = ['Total likes', 'Total page reactions', 'Page post engagements', 'Total reach',]

# Create 'High_Performing' column based on median engagement_rate in df1
# Using 'engagement_rate' instead of 'Engagement Rate'
df1['High_Performing'] = df1['Page post engagements'] > df2['Engagement'].median()

# Convert to binary 0/1
df1['High_Performing'] = df1['High_Performing'].astype(int)

# Splitting data into training and testing sets
# Using df1 for both X and y since we are predicting High_Performing based on df1 features
X = df1[features]
y = df1['High_Performing']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Logistic Regression Model
log_model = LogisticRegression()
log_model.fit(X_train_scaled, y_train)
log_predictions = log_model.predict(X_test_scaled)

# Decision Tree Model
dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)
dt_model.fit(X_train, y_train)
dt_predictions = dt_model.predict(X_test)

# Evaluating Models
log_accuracy = accuracy_score(y_test, log_predictions)
dt_accuracy = accuracy_score(y_test, dt_predictions)

print("Logistic Regression Accuracy:", log_accuracy)
print("Decision Tree Accuracy:", dt_accuracy)
print("Classification Report (Logistic Regression):\n", classification_report(y_test, log_predictions))
print("Classification Report (Decision Tree):\n", classification_report(y_test, dt_predictions))

# Confusion Matrices
print("Confusion Matrix (Logistic Regression):\n", confusion_matrix(y_test, log_predictions))
print("Confusion Matrix (Decision Tree):\n", confusion_matrix(y_test, dt_predictions))